\newpage
% ===================================================================
% ABSTRACT - ITALIAN
% ===================================================================
\begin{otherlanguage}{italian}
\section*{Abstract in italian}

L'adozione crescente dei \textbf{Veicoli Elettrici (EV)} in concomitanza con la sempre maggiore diffusione di \textbf{Fonti di Energia Rinnovabile (RES)} non programmabili, presenta sfide significative alla \textbf{stabilità} e all'\textbf{efficienza della rete elettrica}. La tecnologia \textbf{Vehicle-to-Grid (V2G)} emerge come soluzione fondamentale, trasformando gli EV da carichi passivi a \textbf{risorse energetiche flessibili} capaci di fornire vari \textbf{servizi di rete}. Questa tesi affronta il complesso \textbf{problema di ottimizzazione multi-obiettivo} della gestione intelligente di carica e scarica degli EV, che intrinsecamente implica un equilibrio tra \textbf{benefici economici}, \textbf{esigenze di mobilità dell'utente}, \textbf{preservazione della salute della batteria} e \textbf{stabilità della rete} in condizioni stocastiche.
\\
Di fronte alla complessa sfida di ottimizzare la ricarica degli EV in scenari V2G, un approccio che si limita a un singolo modello di controllo, come il Deep Q-Networks (DQN), risulterebbe inadeguato. La natura del problema, caratterizzata da molteplici obiettivi contrastanti  e da una profonda incertezza; richiede un'analisi comparativa e rigorosa di un'ampia gamma di strategie di controllo.
Per questo motivo, la ricerca si concentra sulla valutazione di un portafoglio diversificato di algoritmi, che include numerosi modelli di Deep Reinforcement Learning (DRL), approcci euristici e il Model Predictive Control (MPC). Questo metodo consente di mappare in modo completo il panorama delle soluzioni, identificando i punti di forza e di debolezza di ciascun approccio in relazione alle diverse sfaccettature del problema V2G.
\\
Il lavoro di tesi non si focalizza su un singolo metodo, ma adotta un approccio comparativo su larga scala perché: \noindent\textbf{non esiste una soluzione unica}: la complessità del problema V2G rende improbabile che un solo algoritmo sia ottimale in tutte le condizioni.\noindent 
\textbf{Si ricercano i compromessi}: l'obiettivo è comprendere i trade-off tra l'efficienza dei dati, la stabilità dell'addestramento, la robustezza all'incertezza e la complessità computazionale delle diverse famiglie di algoritmi.
\noindent\textbf{La validazione è più rigorosa}: confrontare i modelli di DRL non solo tra loro ma anche con benchmark consolidati come le euristiche e l'MPC fornisce una misura molto più credibile del loro reale valore aggiunto.

\end{otherlanguage}
\newpage
% ===================================================================
% ABSTRACT - ENGLISH
% ===================================================================
\section*{Abstract}
The growing adoption of \textbf{Electric Vehicles (EVs)}, combined with the increasing penetration of intermittent \textbf{Renewable Energy Sources (RESs)}, presents significant challenges to the \textbf{stability} and \textbf{efficiency} of the power grid.The \textbf{V2G} technology emerges as a key solution, transforming EVs from passive loads into \textbf{flexible energy resources} capable of providing various \textbf{grid services}. This thesis addresses the complex \textbf{multi-objective optimization problem} of smart EV charging and discharging, which requires balancing \textbf{economic benefits}, \textbf{user mobility needs}, \textbf{battery health preservation}, and \textbf{grid stability} under stochastic conditions.
\\
Given the complexity of optimizing EV charging in V2G scenarios, relying on a single control model is insufficient. The nature of the problem, characterized by multiple conflicting objectives (economic benefits, user needs, battery health, grid stability) and profound uncertainty, demands a rigorous comparative analysis of a wide range of control strategies.
\\
For this reason, the research focuses on evaluating a diverse portfolio of algorithms, including numerous Deep Reinforcement Learning (DRL) models, heuristic approaches, and Model Predictive Control (MPC). This method allows for a complete mapping of the solution space, identifying the strengths and weaknesses of each approach in relation to the different facets of the V2G problem.
\noindent
In short, this thesis adopts a broad-spectrum comparative approach for several reasons:
\textbf{No Single Solution}: the complexity of the V2G problem makes it unlikely that a single algorithm can be optimal in all conditions.
\textbf{Understanding Trade-offs}: the goal is to understand the trade-offs between data efficiency, training stability, robustness to uncertainty, and the computational complexity of different algorithm families.
\textbf{Rigorous Validation}: comparing DRL models not only against each other but also against established benchmarks like heuristics and MPC provides a more credible measure of their true value.





\newpage
% \chapter*{List of Acronyms} % If you are using the 'book' or 'report' class
\section*{List of Acronyms} % If you are using the 'article' class
\addcontentsline{toc}{chapter}{List of Acronyms} % Adds the list to the table of contents

\begin{longtable}{ll}
\textbf{Acronym} & \textbf{Description} \\
\hline
\endhead % This header will be repeated on every page of the list

% --- Category: Artificial Intelligence & Control ---
\multicolumn{2}{l}{\textbf{Artificial Intelligence \& Control}} \\
A2C & Advantage Actor-Critic \\
A3C & Asynchronous Advantage Actor-Critic \\ 
AC & Actor-Critic \\
AI & Artificial Intelligence \\
ARS & Augmented Random Search \\
CL & Curriculum Learning \\
DDPG & Deep Deterministic Policy Gradient \\
DQN & Deep Q-Networks \\
DRL & Deep Reinforcement Learning \\
LQR & Linear Quadratic Regulator \\
MILP & Mixed-Integer Linear Programming \\
MPC & Model Predictive Control \\
NN & Neural Network \\
PER & Prioritized Experience Replay \\
PPO & Proximal Policy Optimization \\
RL & Reinforcement Learning \\
SAC & Soft Actor-Critic \\
TD3 & Twin-Delayed Deep Deterministic Policy Gradient \\
TQC & Truncated Quantile Critics \\
TRPO & Trust Region Policy Optimization \\
\hline

% --- Category: Electric Vehicles and Charging ---
\multicolumn{2}{l}{\textbf{Electric Vehicles \& Charging}} \\
AFAP & As Fast As Possible (Heuristic) \\
ALAP & As Late As Possible (Heuristic) \\
CPO & Charge Point Operator \\
EV & Electric Vehicle \\
SoC & State of Charge \\
SoH & State of Health \\
V2B & Vehicle-to-Building \\
V2G & Vehicle-to-Grid \\
V2H & Vehicle-to-Home \\
V2V & Vehicle-to-Vehicle \\
VPP & Virtual Power Plant \\
\hline

% --- Category: Metrics and Technical Parameters ---
\multicolumn{2}{l}{\textbf{Metrics \& Technical Parameters}} \\
AC  & Alternating Current  \\
DC  & Direct Current  \\
CC  & Constant Current \\
CV  & Constant Voltage  \\
DoD & Depth of Discharg \\
MSE & Mean Square Error  \\
RMSE & Root Mean Square Error \\
\end{longtable}

