% ===================================================================
% CHAPTER 3: The EV2Gym Simulation Framework
% ===================================================================
\chapter{An Enhanced V2G Simulation Framework for Robust Control}
\label{chap:ev2gym}

Developing, validating, and benchmarking advanced control algorithms for Vehicle-to-Grid (V2G) systems presents significant challenges. Real-world experimentation is often impractical due to high costs, logistical constraints, and potential risks to grid stability and vehicle hardware. A realistic, flexible, and standardized simulation environment is therefore essential. This thesis builds upon \textbf{EV2Gym}, an open-source simulator designed for V2G smart charging research \footcite{orfanoudakis2024ev2gym}. The work presented here extends the original framework substantially, transforming it into a high-fidelity \textbf{digital twin} suitable not only for single-scenario optimization, but also for developing and rigorously evaluating \textbf{robust, generalist control agents}.

\noindent
The enhanced framework supports two complementary modes of experimentation: detailed analysis of agents specialized for a single environment, and a novel methodology for training and testing agents capable of generalizing across multiple diverse and unpredictable scenarios. This chapter presents the extended architecture, its data-driven models, and its evaluation capabilities, establishing the methodological foundation for subsequent chapters.

\section{Core Simulator Architecture}
The framework maintains the modular architecture of EV2Gym, which mirrors the key entities of a real-world V2G system. It is built on the OpenAI Gym (now Gymnasium) API, which provides a standardized agent-environment interface based on states, actions, and rewards \footcite{brockman2016openai}.

\begin{figure}[H]
    \centering
   
    \includegraphics[width=0.8\linewidth]{Diagram_charge.png}
    \caption{Diagram of charging and discharging scheduling for EVs. \footcite{Dou}.}
    \label{fig:rl_cahrg}
\end{figure}

The architecture consists of several interacting components:
\begin{itemize}
    \item \textbf{Charge Point Operator (CPO):} The central management component of the simulation, responsible for controlling the charging infrastructure and serving as the primary interface for the control algorithm (the DRL agent). The CPO aggregates system state information and dispatches control actions to individual chargers.
    \item \textbf{Chargers:} Digital representations of physical charging stations, configurable by type (AC/DC), maximum power, and efficiency. This enables simulation of heterogeneous charging infrastructures.
    \item \textbf{Power Transformers:} These components model the physical connection points to the grid, aggregating the electrical load from multiple chargers. They enforce the physical power limits of the local distribution network and can model inflexible base loads (e.g., buildings) and local renewable generation (e.g., solar panels).
    \item \textbf{Electric Vehicles (EVs):} Dynamic and autonomous agents, each defined by its battery capacity, power limits, current and desired energy levels, and specific arrival and departure times.
\end{itemize}

The simulation process follows a reproducible three-phase structure: (1) \textbf{Initialization} from a comprehensive YAML configuration file, (2) a discrete-time \textbf{Simulation Loop} where the agent interacts with the environment, and (3) a final \textbf{Evaluation and Visualization} phase that generates standardized performance metrics.

\subsection{Software Implementation and Project Structure}
\label{sec:software_implementation}
The practical implementation is organized within a modular Python package named \texttt{ev2gym}. This structure promotes code reusability and separation of concerns. High-level experimentation scripts, such as \texttt{run\_experiments.py} and \texttt{train\_mpc\_approximator.py}, reside in the project's root directory and orchestrate experiments by utilizing the core functionalities provided by the \texttt{ev2gym} package.

The key subdirectories within the \texttt{ev2gym} package are:
\begin{itemize}
    \item \texttt{baselines/}: Contains implementations for all non-RL controllers, including rule-based heuristics (in \texttt{heuristics.py}) and all variants of the Model Predictive Controllers (in \texttt{pulp\_mpc.py}).
    \item \texttt{rl\_agent/}: The central location for all Reinforcement Learning logic, containing modules for state vector construction (\texttt{state.py}), the library of available reward functions (\texttt{reward.py}), and the implementation of custom RL algorithms (\texttt{custom\_algorithms.py}).
    \item \texttt{utilities/}: A collection of helper functions and utility classes used across the entire framework.
    \item \texttt{models/}: Designated for storing serialized, pre-trained machine learning models, such as the Random Forest model used by the Approximate-Explicit MPC.
\end{itemize}

This modular software design allows for independent development and testing of different components, such as control algorithms and reward functions, while maintaining a consistent and unified simulation environment.

\section{Core Physical Models}
The simulation's fidelity depends on its detailed, empirically validated models, which are necessary for developing control strategies robust enough for real-world application.

\subsection{EV Model and Charging/Discharging Dynamics}
The framework implements a realistic two-stage charging/discharging model that captures the non-linear behavior of lithium-ion batteries, simulating both the \textbf{constant current (CC)} and \textbf{constant voltage (CV)} phases. Each EV is defined by a comprehensive parameter set: maximum capacity ($E_{max}$), a minimum safety capacity ($E_{min}$), separate power limits for charging and discharging ($P_{ch}^{max}, P_{dis}^{max}$), and distinct efficiencies for each process ($\eta_{ch}, \eta_{dis}$).

\subsection{Battery Degradation Model}
To address the critical issue of battery health in V2G operations, the simulator incorporates a semi-empirical battery degradation model. It quantifies capacity loss ($Q_{lost}$) as the sum of two primary aging mechanisms \footcite{orfanoudakis2024ev2gym}: calendar aging and cyclic aging.

\noindent
\begin{itemize}
    \item \textbf{Calendar Aging ($d_{cal}$):} Time-dependent capacity loss, influenced by the battery's average State of Charge (SoC) and temperature ($\Theta$). The formula is:
    \begin{equation}
        d_{cal} = 0.75 \cdot (\epsilon_0 \cdot \overline{SoC} - \epsilon_1) \cdot e^{-\epsilon_2/\Theta} \cdot \frac{t_{days}}{(t_{days}+1)^{0.25}}
    \end{equation}
    
    \item \textbf{Cyclic Aging ($d_{cyc}$):} Wear resulting from charge/discharge cycles, dependent on energy throughput ($E_{exchanged}$), depth-of-cycle (implicitly via $\overline{SoC}$), and the total accumulated charge ($Q_{acc}$). The formula is:
    \begin{equation}
        d_{cyc} = (\zeta_0 + \zeta_1 \cdot |\overline{SoC}-0.5|) \cdot \frac{E_{exchanged}}{\sqrt{Q_{acc}}}
    \end{equation}
\end{itemize}

\noindent
The total capacity loss is the sum $Q_{lost} = d_{cal} + d_{cyc}$. This integrated model enables direct quantification of how different control strategies impact the battery's long-term State of Health (SoH), supporting the training of agents that balance profitability with battery preservation.

\noindent
A key feature of this framework is that the physical parameters for this model ($\epsilon_0, \epsilon_1, \epsilon_2, \zeta_0, \zeta_1, Q_{acc}$) are not fixed. They can be empirically calibrated from real-world experimental data using the provided \texttt{Fit\_battery.py} script, as detailed in Section \ref{sec:sim_architecture}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Unified Experimentation and Evaluation Workflow}
A key contribution of this thesis is the development of a unified and powerful experimentation workflow, orchestrated by the main script \\
\noindent
\texttt{run\_experiments.py}. This script replaces the previous fragmented approach, providing a single, interactive interface to manage the entire lifecycle of training, benchmarking, and evaluation for V2G control agents. This workflow is designed to be both flexible for research and rigorous for evaluation, supporting the dual goals of developing specialized and generalized agents.

\subsection{Orchestration via \texttt{run\_experiments.py}}
The \texttt{run\_experiments.py} script acts as the central hub for all experimentation. It guides the user through an interactive command-line process, ensuring consistency and reproducibility. The key steps are:
\begin{enumerate}
    \item \textbf{Algorithm Selection:} The user can select from a predefined list of algorithms to benchmark. This includes Deep Reinforcement Learning agents (e.g., SAC, DDPG+PER, TQC), classical optimization methods (Model Predictive Control), and rule-based heuristics (e.g., Charge As Fast As Possible).
    \item \textbf{Scenario Selection:} The script automatically detects all available \texttt{.yaml} configuration files, allowing the user to choose one or more scenarios for the experiment. This choice determines the mode of operation (single-domain vs. multi-scenario).
    \item \textbf{Reward Function Selection:} The framework's flexibility is enhanced by allowing the user to dynamically select the reward function for the RL agents from the \texttt{reward.py} module.
    \item \textbf{Training and Benchmarking:} Based on the user's selections, the script proceeds to the optional training phase and then to a comprehensive benchmark, saving all results in a timestamped directory.
\end{enumerate}

\subsection{Dual-Mode Training: Specialists and Generalists}
The new workflow elegantly unifies the training of both "specialist" and "generalist" agents, a concept previously handled by separate scripts. The behavior is determined implicitly by the number of selected scenarios:
\begin{itemize}
    \item \textbf{Single-Domain Specialization:} If the user selects a single scenario, the script trains an RL agent exclusively on that environment. This produces a specialist agent, optimized to extract maximum performance from a specific, known set of conditions (e.g., a particular charging station topology and price profile).
    \item \textbf{Multi-Scenario Generalization:} If multiple scenarios are selected, the script automatically utilizes the \texttt{MultiScenarioEnv} wrapper. This custom Gymnasium environment dynamically switches between the different selected configurations at the start of each training episode. This process forces the agent to learn a robust and generalizable policy that performs well across a wide range of conditions, preventing overfitting to any single scenario. To handle the technical challenge of varying observation and action space sizes across scenarios, a \texttt{CompatibilityWrapper} is used to pad and slice the state-action vectors, enabling a single neural network policy to control heterogeneous environments.
\end{itemize}

\subsection{Reproducible Benchmarking and Evaluation}
To ensure a fair and scientifically valid comparison, the \texttt{run\_benchmark} function implements a rigorous evaluation protocol. For each scenario, it first generates a "replay" file containing the exact sequence of stochastic events (e.g., EV arrivals, energy demands). This exact same sequence is then used to evaluate every algorithm, eliminating randomness as a factor in performance differences. The script runs multiple simulations for statistical robustness, aggregates the mean results, and automatically generates a suite of comparative plots, including overall performance metrics and detailed battery degradation analyses.

\subsection{Interactive Web-Based Dashboard}
\label{sec:streamlit_app}
To complement the command-line-driven workflow, the project includes an interactive web-based dashboard built with the Streamlit library, executed via the \texttt{streamlit\_app.py} script. This graphical user interface (GUI) serves two primary functions, significantly enhancing usability and accessibility for experimentation and results analysis.

\subsubsection{Simulation Orchestrator}
The first part of the dashboard acts as a GUI wrapper for the \texttt{run\_experiments.py} script. It provides a user-friendly web form where users can:
\begin{itemize}
    \item Select which algorithms to benchmark from a multi-select list.
    \item Choose one or more scenarios to test.
    \item Pick a specific reward function for the RL agents from a dropdown menu.
    \item Set simulation parameters, such as the number of evaluation runs.
    \item Toggle optional steps, like running the \texttt{Fit\_battery.py} calibration or enabling RL model training.
\end{itemize}
Upon clicking the "Run Simulation" button, the application constructs the equivalent command-line arguments and executes \texttt{run\_experiments.py} as a subprocess. It captures and displays the console output in real-time on the web page, providing a seamless user experience without requiring direct terminal interaction.

\subsubsection{Results Visualizer}
The second part of the dashboard is a dedicated results browser. It automatically scans the \texttt{results/} directory and presents a list of all completed benchmark runs (organized by timestamp). The user can select a specific benchmark, and the application will find and display all the generated plots (e.g., performance comparisons, battery degradation graphs) directly on the page. This feature allows for quick and convenient inspection and comparison of outcomes from different experiments.

\section{Evaluation Metrics}
To ensure a fair and comprehensive comparison, all algorithms are evaluated against an identical set of pre-generated scenarios through a "replay" mechanism. The \textbf{mean} and \textbf{standard deviation} of performance are calculated across multiple simulation runs. The key metrics include:

\begin{itemize}
    \item \textbf{Total Profit (\$):} The net economic outcome, calculated as revenue from energy sales minus the cost of energy purchases.
    \[
    \Pi_{\text{total}} = \sum_{t=0}^{T_{\text{sim}}} \sum_{i=1}^{N} \left( C_{\text{sell}}(t) P_{\text{dis},i}(t) - C_{\text{buy}}(t) P_{\text{ch},i}(t) \right) \Delta t
    \]
    
    \item \textbf{Tracking Error (RMSE, kW):} For grid-balancing scenarios, this measures the root-mean-square error between the fleet's aggregated power and a target setpoint.
    \[
    E_{\text{track}} = \sqrt{\frac{1}{T_{\text{sim}}} \sum_{t=0}^{T_{\text{sim}}-1} \left( P_{\text{setpoint}}(t) - P_{\text{total}}(t) \right)^2}
    \]
    
    \item \textbf{User Satisfaction (Average):} The fraction of energy delivered compared to what was requested by the user, averaged across all EV sessions. A score of 1 indicates perfect service.
    \[
    US_{\text{avg}} = \frac{1}{N_{\text{EVs}}} \sum_{k=1}^{N_{\text{EVs}}} \min \left(1, \frac{E_k(t_k^{\text{dep}})}{E_k^{\text{des}}} \right)
    \]
    
    \item \textbf{Transformer Overload (kWh):} The total energy that exceeded \\ \noindent 
the transformer's rated power limit. An ideal controller should achieve a value of 0.
    \[
    O_{\text{tr}} = \sum_{t=0}^{T_{\text{sim}}} \sum_{j=1}^{N_T} \max(0, P_j^{\text{tr}}(t) - P_j^{\text{tr,max}}) \cdot \Delta t
    \]
    
    \item \textbf{Battery Degradation (\$):} The estimated monetary cost of battery aging due to both cyclic and calendar effects.
    \[
    D_{\text{batt}} = \sum_{k=1}^{N_{\text{EVs}}} (\text{CyclicCost}_k + \text{CalendarCost}_k)
    \]
\end{itemize}

\section{Simulator Implementation Details}
\label{sec:sim_architecture}
During the analysis and implementation of new metrics, fundamental details about the \texttt{EV2Gym} simulator's architecture emerged, which warrant documentation. The configuration of Electric Vehicles (EVs) and the calculation of their degradation follow a specific logic dependent on a key parameter in the \texttt{.yaml} configuration files.

\subsubsection{Vehicle Definition Modes}
The simulator operates in two distinct modes, controlled by the boolean flag \texttt{heterogeneous\_ev\_specs}:
\begin{itemize}
    \item \textbf{Heterogeneous Mode (\texttt{True}):} In this mode, the simulator ignores the default vehicle specifications in the \texttt{.yaml} file. Instead, it loads a list of vehicle profiles from an external JSON file, specified by the \texttt{ev\_specs\_file} parameter\\ \noindent (e.g., \texttt{ev\_specs\_v2g\_enabled2024.json}). This allows for the creation of a realistic fleet with diverse battery capacities, charging powers, and efficiencies. For instance, the fleet may include a \textbf{Peugeot 208} with a 46.3 kWh battery and a 7.4 kW charge rate, alongside a \textbf{Volkswagen ID.4} with a 77 kWh battery and an 11 kW charge rate. A vehicle is randomly selected from this list for each new arrival event.
    \item \textbf{Homogeneous Mode (\texttt{False}):} In this mode, the external JSON file is ignored. All vehicles created in the simulation are identical, and their characteristics are defined exclusively by the \texttt{ev:} block within the \texttt{.yaml} configuration file. The \texttt{battery\_capacity} parameter in this block becomes the single source of truth for the entire fleet.
\end{itemize}

\subsubsection{Empirical Calibration of the Degradation Model}
A significant enhancement in this work is the move towards a more physically representative and flexible battery degradation model. While the underlying semi-empirical model for calendar and cyclic aging remains, the methodology for parameterizing it has been fundamentally improved, addressing previous inconsistencies.
\noindent
This is achieved through the \texttt{Fit\_battery.py} script, a new utility for empirical model calibration. The script implements the following workflow:
\begin{enumerate}
    \item \textbf{Data Loading:} It loads time-series data from real-world battery aging experiments. The expected data includes measurements of capacity loss over time, along with contextual variables like state of charge (SoC), temperature, and energy throughput.
    \item \textbf{Model Fitting:} Using the \texttt{curve\_fit} function from the SciPy library, the script fits the parameters of the \texttt{Qlost\_model} (which combines calendar and cyclic aging) to the empirical data. This optimization process finds the physical constants (e.g., $\epsilon_0, \zeta_0$) that best explain the observed degradation.
    \item \textbf{Parameter Export:} The script outputs the calibrated parameters. These values can then be used directly in the simulator's configuration, ensuring that the degradation model for a specific EV fleet is grounded in experimental evidence for that battery type.
\end{enumerate}
\noindent
This calibration workflow, integrated optionally into the main \texttt{run\_experiments.py} script, elevates the simulation's fidelity. It allows the framework to move beyond a single, fixed degradation model (previously calibrated for a 78 kWh battery) and enables the creation of high-fidelity digital twins for a wide variety of EV batteries, provided that the necessary experimental data is available.


\section{Simulation Framework Components}
The simulation environment is constructed from a set of modular classes, each representing a key physical or logical component of the EV charging ecosystem. This section details the implementation and mathematical underpinnings of each component.

\subsection{Electric Vehicle Model (\texttt{ev.py})}
The \texttt{EV} class is the most fundamental component, encapsulating the state, physical constraints, and charging behavior of a single electric vehicle. It serves as the primary dynamic element within the simulation.

\subsubsection{State and Attribute Representation}
Each EV instance is defined by a set of static and dynamic attributes that govern its behavior throughout its connection period.
\noindent
\begin{itemize}
    \item \textbf{Static Attributes:} These are defined upon the EV's arrival and remain constant. They include the maximum battery capacity ($E^{\text{max}}_i$), a minimum operational capacity ($E^{\text{min}}_i$), maximum AC charging power ($P^{\text{ch,max}}_i$), maximum discharging power ($P^{\text{dis,max}}_i$), charging efficiency ($\eta_{\text{ch}}$), discharging efficiency ($\eta_{\text{dis}}$), arrival time ($t^{\text{arr}}_i$), and departure time ($t^{\text{dep}}_i$).
    \item \textbf{Dynamic State Variables:} The core state variable is the current energy stored in the battery, denoted as $E_{i,t}$ at time step $t$. This state is updated at every simulation step.
    \item \textbf{Goal-Oriented Attributes:} The EV's objective is defined by its desired energy at departure, $E^{\text{des}}_i$. This is used to calculate user satisfaction.
\end{itemize}

\subsubsection{Charging and Discharging Dynamics}
The model implements a sophisticated two-stage charging process to accurately reflect the behavior of lithium-ion batteries, particularly the transition from the constant current (CC) to the constant voltage (CV) phase.

\paragraph{Two-Stage Charging Model (\texttt{\_charge} method).}
The charging rate is not constant up to full capacity. The model captures the characteristic tapering of current as the battery approaches its maximum charge.
\begin{enumerate}
    \item \textbf{Constant Current (CC) Phase:} When the State of Charge ($SoC_{i,t}$) is below a transition threshold, $SoC^{\text{trans}}$, the battery charges at a constant power. The rate of change of energy is limited by both the pilot signal from the charger, $P^{\text{pilot}}_{i,t}$, and the EV's own maximum charging power, $P^{\text{ch,max}}_i$. The effective charging power is $P^{\text{ch}}_{i,t} = \min(P^{\text{pilot}}_{i,t}, P^{\text{ch,max}}_i)$. The energy evolution is:
    \begin{equation}
        E_{i,t} = E_{i,t-1} + \eta_{\text{ch}} \cdot P^{\text{ch}}_{i,t} \cdot \frac{\Delta t}{60}
    \end{equation}
    where $\Delta t$ is the timescale in minutes.
    
    \item \textbf{Constant Voltage (CV) Phase:} Once $SoC_{i,t}$ exceeds $SoC^{\text{trans}}$, the charging power begins to decrease, even if the pilot signal remains high. The implementation in the \texttt{\_charge} method approximates this tapering effect using an exponential decay function. The model calculates a new transition SoC based on the pilot signal and then computes the new SoC using a formula that ensures a smooth, decaying charge rate as the SoC approaches 100\%. This prevents unrealistic assumptions of constant maximum power charging until the battery is full.
\end{enumerate}

\paragraph{Discharging Model (\texttt{\_discharge} method).}
Discharging is modeled as a linear process, constrained by the EV's maximum discharge power and the battery's minimum energy level. The energy delivered to the grid, $P^{\text{dis}}_{i,t}$, results in a larger energy withdrawal from the battery due to inefficiency:
\begin{equation}
    E_{i,t} = E_{i,t-1} + \frac{P^{\text{dis}}_{i,t}}{\eta_{\text{dis}}} \cdot \frac{\Delta t}{60}
\end{equation}
where $P^{\text{dis}}_{i,t}$ is negative by convention. The operation is constrained such that $E_{i,t} \ge E^{\text{min}}_i$.

\subsubsection{User Satisfaction Metric}
Upon departure at time $t^{\text{dep}}_i$, the performance of the charging service is quantified by a user satisfaction metric, $S_i$. This is defined as the ratio of the final energy level to the desired energy level, capped at 100\%.
\begin{equation}
    S_i = \min\left(1, \frac{E_{i, t^{\text{dep}}_i}}{E^{\text{des}}_i}\right)
\end{equation}
This metric provides a crucial feedback signal for control algorithms, penalizing strategies that fail to meet user requirements.

\subsection{Charging Station Model (\texttt{ev\_charger.py})}
The \texttt{EV\_Charger} class acts as an intermediary between the grid infrastructure and the individual EVs. It manages a collection of charging ports and enforces its own set of physical and operational constraints.

\subsubsection{Role and Attributes}
A charging station (CS) is defined by its number of ports ($N_{\text{ports}}$), its maximum aggregate charging and discharging currents ($I^{\text{max,ch}}_{\text{CS}}$, $I^{\text{max,dis}}_{\text{CS}}$), its operating voltage ($V$), and the number of phases. It serves as a local aggregation point for power and energy.

\subsubsection{Operational Logic (\texttt{step} method)}
At each simulation step, the \texttt{step} method executes the core logic of the charging station:
\begin{enumerate}
    \item \textbf{Action Translation:} It receives a normalized action vector $a_t \in [-1, 1]^{N_{\text{ports}}}$. For each port $j$, it translates the normalized action $a_{j,t}$ into a physical pilot current signal, $I^{\text{pilot}}_{j,t}$.
    \begin{align}
        I^{\text{pilot}}_{j,t} = 
        \begin{cases} 
            a_{j,t} \cdot I^{\text{max,ch}}_{\text{CS}} & \text{if } a_{j,t} > 0 \\
            a_{j,t} \cdot |I^{\text{max,dis}}_{\text{CS}}| & \text{if } a_{j,t} < 0 \\
            0 & \text{if } a_{j,t} = 0
        \end{cases}
    \end{align}
    \item \textbf{EV Interaction:} It passes this pilot current to the \texttt{step} method of the corresponding connected \texttt{EV} instance, which then calculates its actual power exchange based on its internal two-stage model.
    \item \textbf{Power Aggregation:} It aggregates the actual power, $P_{j,t}$, from all its ports to determine its total power exchange with the grid at that time step.
    \begin{equation}
        P_{\text{CS},t} = \sum_{j=1}^{N_{\text{ports}}} P_{j,t}
    \end{equation}
    \item \textbf{Economic Calculation:} It calculates the net profit for the time step based on the aggregated energy and real-time electricity prices ($c^{\text{buy}}_t, c^{\text{sell}}_t$).
    \item \textbf{Departure Management:} It checks for departing EVs, collects their final user satisfaction scores, and frees up the corresponding ports.
\end{enumerate}

\subsection{Transformer Model (\texttt{transformer.py})}
The \texttt{Transformer} class represents a critical piece of grid infrastructure, modeling the point of common coupling for a group of charging stations and other local loads. Its primary function is to enforce an aggregate power limit.

\subsubsection{Model Components}
Each transformer is characterized by its maximum power capacity, $P^{\text{max}}_{\text{TR}}$. It also manages two external time-series data streams:
\begin{itemize}
    \item \textbf{Inflexible Load ($P^{\text{inflex}}_{t}$):} Represents the background power consumption from other sources (e.g., buildings) connected to the same transformer.
    \item \textbf{Solar Power ($P^{\text{PV}}_{t}$):} Represents local photovoltaic generation, which acts as a negative load.
\end{itemize}

\subsubsection{Core Functionality}
The transformer's logic is centered around monitoring its total load and checking for capacity violations.
\noindent
\paragraph{Load Aggregation.} At each time step $t$, the total power flowing through the transformer, $P_{\text{TR},t}$, is the algebraic sum of the inflexible load, the solar generation, and the sum of the power from all charging stations connected to it.
\begin{equation}
    P_{\text{TR},t} = P^{\text{inflex}}_{t} + P^{\text{PV}}_{t} + \sum_{i \in \text{CSs connected to TR}} P_{\text{CS},i,t}
\end{equation}
\paragraph{Overload Detection.} The critical function is \texttt{is\_overloaded}, which returns true if the absolute total power exceeds the transformer's rating. This condition serves as a primary constraint for the control problem.
\begin{equation}
    \text{Overload} \iff |P_{\text{TR},t}| > P^{\text{max}}_{\text{TR}}
\end{equation}
\paragraph{Forecasting with Uncertainty.} The model includes methods (\texttt{generate\_...\_forecast}) to simulate imperfect knowledge of future loads and generation. It creates forecasts by taking the true profiles and adding zero-mean Gaussian noise, where the standard deviation is a configurable percentage of the true value. This allows for the development of robust control strategies that can handle prediction errors.


\subsection{Main Gym Environment (\texttt{ev2gym\_env.py})}
The \texttt{EV2Gym} class is the central orchestrator of the entire simulation. It integrates all the aforementioned physical models into a cohesive whole and exposes it through the standardized \texttt{gymnasium.Env} interface, making it compatible with a wide range of reinforcement learning algorithms.

\subsubsection{Environment Structure and Main Loop}
The class manages the high-level simulation flow.
\noindent
\paragraph{Initialization (\texttt{\_\_init\_\_}).} Upon creation, the environment reads a configuration file to instantiate all the necessary components: it creates the specified number of \texttt{Transformer} and \texttt{EV\_Charger} objects, loads the EV arrival scenarios, and sets up electricity price profiles.
\noindent
\paragraph{Simulation Step (\texttt{step(actions)}).} This method drives the simulation forward by one time step ($\Delta t$). The sequence of operations is as follows:
\begin{enumerate}
    \item It receives a single, flat action vector containing the control signals for every charging port in the entire system.
    \item It slices this vector and passes the appropriate actions to each \texttt{EV\_Charger}'s \texttt{step} method.
    \item This triggers the \texttt{step} methods of all connected \texttt{EV}s, updating their internal states ($E_{i,t}$).
    \item It aggregates the resulting power at each \texttt{Transformer} and checks for overload conditions.
    \item It processes the EV queue, spawning new EVs that are scheduled to arrive at the next time step.
    \item It computes a scalar reward signal using a user-defined reward function.
    \item It constructs the next state observation using a user-defined state representation function.
    \item It checks for termination conditions (e.g., simulation end, constraint violation).
    \item It returns the standard `(observation, reward, terminated, truncated, info)` tuple.
\end{enumerate}
\paragraph{Reset (\texttt{reset}).} This method re-initializes the entire environment to a starting state, allowing for the start of a new simulation episode, which could represent a new day or a different random scenario.




\section{Reinforcement Learning Formulation}
The control problem is formalized as a Markov Decision Process (MDP), defined by the tuple $(S, A, P, R, \gamma)$.

\subsection{State Space ($S$)}
The state $s_t \in S$ is a feature vector providing a snapshot of the environment at time $t$. A representative state, as defined in modules like \\ \noindent \texttt{V2G\_profit\_max\_loads.py}, includes:
\[
 s_t = [t, P_{\text{total}}(t-1), \mathbf{c}(t, H), \mathbf{L}_1(t, H), \mathbf{PV}_1(t, H), \dots, \mathbf{s}^{\text{EV}}_1(t), \dots, \mathbf{s}^{\text{EV}}_N(t)]^T
\]
where the components are:
\begin{itemize}
    \item $t$: The current time step.
    \item $P_{\text{total}}(t-1)$: The aggregated power from the previous time step.
    \item $\mathbf{c}(t, H)$: A vector of \textbf{predicted future} electricity prices over a horizon $H$.
    \item $\mathbf{L}_j(t, H), \mathbf{PV}_j(t, H)$: Forecasts for inflexible loads and solar generation.
    \item $\mathbf{s}^{\text{EV}}_i(t) = [\text{SoC}_i(t), t^{\text{dep}}_i - t]$: Key information for each EV $i$, including its State of Charge and remaining time until departure.
\end{itemize}

\subsection{Action Space ($A$)}
The action $a_t \in A$ is a continuous vector in $\mathbb{R}^N$, where $N$ is the number of chargers. For each charger $i$, the command $a_i(t) \in [-1, 1]$ is a normalized value that is translated into a power command:
\begin{itemize}
    \item If $a_i(t) > 0$, the EV is charging: $P_i(t) = a_i(t) \cdot P^{\text{max}}_{\text{charge}, i}$.
    \item If $a_i(t) < 0$, the EV is discharging (V2G): $P_i(t) = a_i(t) \cdot P^{\text{max}}_{\text{discharge}, i}$.
\end{itemize}

\subsection{Reward Function}
The reward function $R(t)$ encodes the objectives of the control agent. The framework allows for the selection of different reward functions from the \texttt{reward.py} module to suit various goals. Key examples include:
\begin{itemize}
    \item \textbf{Profit Maximization with Penalties} (\texttt{ProfitMax\_TrPenalty\_UserIncentives}): This function creates a balance between economic gain and physical constraints.
    \[
    R(t) = \underbrace{\text{Profit}(t)}_{\text{Economic Gain}} - \underbrace{\lambda_1 \cdot \text{Overload}(t)}_{\text{Grid Penalty}} - \underbrace{\lambda_2 \cdot \text{Unsatisfaction}(t)}_{\text{User Penalty}}
    \]
    The agent is rewarded for profit but penalized for overloading transformers and for failing to meet the charging needs of departing drivers.
    
    \item \textbf{Squared Tracking Error} (\texttt{SquaredTrackingErrorReward}): Used for grid service applications where precision is paramount.
    \[
    R(t) = - \left( P_{\text{setpoint}}(t) - \sum_{i=1}^N P_i(t) \right)^2
    \]
    The reward is the negative squared error from the power setpoint, incentivizing the agent to minimize this error at all times.
\end{itemize}
\noindent
By using this enhanced framework, this thesis moves beyond single-scenario optimization to develop and validate an intelligent V2G control agent that is not only high-performing but also robust, adaptable, and ready for the complexities of real-world deployment.



\input{Reinforcement_learning}


\input{pulp_mpc}
